{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbRrWtX0PXVr"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IST-DASLab/sparsegpt/blob/master/demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMUp4UrWjp-8"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdbD9blm6j_r",
        "outputId": "0af5ba55-ecc0-4e7d-a44b-503c77c31f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhSblKg_jter"
      },
      "source": [
        "Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nCz469NhV3c",
        "outputId": "040c549e-26be-4eba-cbe4-b6cf7c804776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sparsegpt'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 46 (delta 22), reused 13 (delta 10), pack-reused 11 (from 1)\u001b[K\n",
            "Receiving objects: 100% (46/46), 26.80 KiB | 13.40 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IST-DASLab/sparsegpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbM_bJODjyBg"
      },
      "source": [
        "### Pruning example\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om0QSLnLj8JN"
      },
      "source": [
        "Below we will show an example of SparseGPT applied to OPT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9NTGmD4iVK7",
        "outputId": "08f81f90-eb4d-4791-d6b6-a956db0558ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sparsegpt\n"
          ]
        }
      ],
      "source": [
        "%cd sparsegpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbiDyjx9j61I"
      },
      "source": [
        "Crerate directory to store prune model(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pJ-jauI-iyvi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p sparse_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGLiExo5Ksc4"
      },
      "source": [
        "We will use `opt.py` script to prune the model.\n",
        "Select one of the following OPT versions to fit into colab (with `bitsandbytes` one should be able to use larger 6.7b and 13b models):\n",
        "* facebook/opt-125m\n",
        "* facebook/opt-350m\n",
        "* facebook/opt-1.3b\n",
        "\n",
        "To prune the model select dataset for calibration (`c4`, `ptb` or `wikitext`). The SparseGPT paper uses `c4` by default.\n",
        "\n",
        "One can prune model to uniform sparsity with SparseGPT either with unstructured pruning or semistructured `N:M` pattern.\n",
        "\n",
        "To apply unstructured pruning specify `--sparsity` - floating point number in `[0, 1]`.\n",
        "\n",
        "For semitstructured specify `--prunen` and `--prunem` arguments - integer numbers.\n",
        "\n",
        "To apply magnitude pruning instead of SparseGPT select `--gmp` option.\n",
        "\n",
        "To apply quantization on top of sparsity specify `--wbits`.\n",
        "\n",
        "In the example below we prune `facebook/opt-125m` to 0.5 unstructured sparsity via SparseGPT. Try different options.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxucjXmCibnI",
        "outputId": "7078f13f-d5ce-41c4-cac9-543dd1e5fa9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-13 17:38:05.154278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-13 17:38:05.173659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-13 17:38:05.179436: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-13 17:38:05.193330: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-13 17:38:06.461245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 651/651 [00:00<00:00, 3.62MB/s]\n",
            "pytorch_model.bin: 100% 251M/251M [00:01<00:00, 232MB/s]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 759kB/s]\n",
            "tokenizer_config.json: 100% 685/685 [00:00<00:00, 3.87MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 3.65MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 42.9MB/s]\n",
            "special_tokens_map.json: 100% 441/441 [00:00<00:00, 2.97MB/s]\n",
            "README.md: 100% 41.1k/41.1k [00:00<00:00, 66.0MB/s]\n",
            "c4-train.00000-of-01024.json.gz: 100% 319M/319M [00:01<00:00, 215MB/s]\n",
            "Generating train split: 356317 examples [00:11, 32332.15 examples/s]\n",
            "c4-validation.00000-of-00008.json.gz: 100% 40.5M/40.5M [00:00<00:00, 124MB/s] \n",
            "Generating validation split: 45576 examples [00:01, 35645.63 examples/s]\n",
            "Starting ...\n",
            "Ready.\n",
            "0 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.31\n",
            "error 13941.1796875\n",
            "0 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 547.5176391601562\n",
            "0 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 14149.169921875\n",
            "0 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 6.390366554260254\n",
            "0 fc1\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 2260.53271484375\n",
            "0 fc2\n",
            "Pruning ...\n",
            "time 0.76\n",
            "error 36.47813415527344\n",
            "1 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.42\n",
            "error 9681.9423828125\n",
            "1 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 641.3023071289062\n",
            "1 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.21\n",
            "error 4021.9521484375\n",
            "1 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 4.026435852050781\n",
            "1 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 6266.025390625\n",
            "1 fc2\n",
            "Pruning ...\n",
            "time 0.74\n",
            "error 14.21982192993164\n",
            "2 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.42\n",
            "error 15796.482421875\n",
            "2 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 1678.2252197265625\n",
            "2 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 14268.8916015625\n",
            "2 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 9.782876968383789\n",
            "2 fc1\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 5071.48291015625\n",
            "2 fc2\n",
            "Pruning ...\n",
            "time 0.86\n",
            "error 10.713717460632324\n",
            "3 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.51\n",
            "error 14278.5732421875\n",
            "3 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.29\n",
            "error 2322.1474609375\n",
            "3 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 14316.123046875\n",
            "3 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 15.892521858215332\n",
            "3 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 3088.41845703125\n",
            "3 fc2\n",
            "Pruning ...\n",
            "time 0.75\n",
            "error 0.482747346162796\n",
            "4 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.42\n",
            "error 27317.13671875\n",
            "4 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.17\n",
            "error 3170.04541015625\n",
            "4 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 29192.6484375\n",
            "4 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 24.25299072265625\n",
            "4 fc1\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 7959.7666015625\n",
            "4 fc2\n",
            "Pruning ...\n",
            "time 0.73\n",
            "error 29.886585235595703\n",
            "5 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.43\n",
            "error 29622.58984375\n",
            "5 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 2877.6640625\n",
            "5 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 34875.9609375\n",
            "5 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 38.594505310058594\n",
            "5 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 8126.0810546875\n",
            "5 fc2\n",
            "Pruning ...\n",
            "time 0.79\n",
            "error 71.30626678466797\n",
            "6 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.82\n",
            "error 31982.791015625\n",
            "6 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 3908.043212890625\n",
            "6 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 33823.671875\n",
            "6 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 48.45915603637695\n",
            "6 fc1\n",
            "Pruning ...\n",
            "time 0.29\n",
            "error 8049.89453125\n",
            "6 fc2\n",
            "Pruning ...\n",
            "time 1.07\n",
            "error 101.66566467285156\n",
            "7 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 39241.19140625\n",
            "7 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 4541.48291015625\n",
            "7 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 39058.3515625\n",
            "7 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 82.68592834472656\n",
            "7 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 10329.494140625\n",
            "7 fc2\n",
            "Pruning ...\n",
            "time 0.73\n",
            "error 137.70272827148438\n",
            "8 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 40046.2421875\n",
            "8 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 6433.265625\n",
            "8 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 44658.7421875\n",
            "8 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 161.2930450439453\n",
            "8 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 14341.58984375\n",
            "8 fc2\n",
            "Pruning ...\n",
            "time 0.74\n",
            "error 228.39495849609375\n",
            "9 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 47155.1875\n",
            "9 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 7610.6767578125\n",
            "9 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 51155.8046875\n",
            "9 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.20\n",
            "error 270.553955078125\n",
            "9 fc1\n",
            "Pruning ...\n",
            "time 0.29\n",
            "error 19697.81640625\n",
            "9 fc2\n",
            "Pruning ...\n",
            "time 0.97\n",
            "error 372.3135070800781\n",
            "10 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 44681.421875\n",
            "10 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 9517.8984375\n",
            "10 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.19\n",
            "error 43798.4140625\n",
            "10 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 262.7840576171875\n",
            "10 fc1\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 24759.40234375\n",
            "10 fc2\n",
            "Pruning ...\n",
            "time 0.79\n",
            "error 580.3178100585938\n",
            "11 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.44\n",
            "error 43898.546875\n",
            "11 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 11820.0712890625\n",
            "11 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 46675.65625\n",
            "11 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.18\n",
            "error 431.5930480957031\n",
            "11 fc1\n",
            "Pruning ...\n",
            "time 0.20\n",
            "error 27321.181640625\n",
            "11 fc2\n",
            "Pruning ...\n",
            "time 0.73\n",
            "error 614.2781372070312\n",
            "model.decoder.embed_tokens.weight tensor(3.8851e-07)\n",
            "model.decoder.embed_positions.weight tensor(0.0005)\n",
            "model.decoder.final_layer_norm.weight tensor(0.)\n",
            "model.decoder.final_layer_norm.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.k_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.k_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.q_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.out_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias tensor(0.)\n",
            "model.decoder.layers.0.fc1.weight tensor(0.5000)\n",
            "model.decoder.layers.0.fc1.bias tensor(0.)\n",
            "model.decoder.layers.0.fc2.weight tensor(0.5000)\n",
            "47.9406418800354\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 46.0MB/s]\n",
            "test-00000-of-00001.parquet: 100% 733k/733k [00:00<00:00, 4.22MB/s]\n",
            "train-00000-of-00001.parquet: 100% 6.36M/6.36M [00:00<00:00, 204MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 657k/657k [00:00<00:00, 112MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 151236.76 examples/s]\n",
            "Generating train split: 100% 36718/36718 [00:00<00:00, 680306.63 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 572206.49 examples/s]\n",
            "wikitext2\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "Perplexity: 36.925953\n",
            "README.md: 100% 4.21k/4.21k [00:00<00:00, 15.7MB/s]\n",
            "ptb_text_only.py: 100% 6.50k/6.50k [00:00<00:00, 24.8MB/s]\n",
            "The repository for ptb_text_only contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ptb_text_only.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] Traceback (most recent call last):\n",
            "  File \"/content/sparsegpt/opt.py\", line 333, in <module>\n",
            "    dataloader, testloader = get_loaders(\n",
            "  File \"/content/sparsegpt/datautils.py\", line 102, in get_loaders\n",
            "    return get_ptb(nsamples, seed, seqlen, model, tokenizer)\n",
            "  File \"/content/sparsegpt/datautils.py\", line 47, in get_ptb\n",
            "    traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2129, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1849, in load_dataset_builder\n",
            "    dataset_module = dataset_module_factory(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1731, in dataset_module_factory\n",
            "    raise e1 from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1681, in dataset_module_factory\n",
            "    ).get_module()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1331, in get_module\n",
            "    trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "    raise ValueError(\n",
            "ValueError: The repository for ptb_text_only contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ptb_text_only.\n",
            "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n"
          ]
        }
      ],
      "source": [
        "!python opt.py facebook/opt-125m c4 --sparsity 0.5 --save sparse_opt/opt-125m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mrOL92aO5xy"
      },
      "source": [
        "Code above prints perplexity on `wikitext2`, `ptb` and `c4` benchmarks in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD9Zkgb-O21A"
      },
      "source": [
        "### Compare generations\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSJIGizLkPm8"
      },
      "source": [
        "Let us compare generations produced by the dense and sparse model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-GzBUGsXic0o"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, OPTForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ub-69himlTpZ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mQJtRPbekmXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "1f0659b7-c99d-47e5-ca8e-c6245da47a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "sparse_opt/opt-125m is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/sparse_opt/opt-125m/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-675c71ab-7be374c7126cda8c23054eaf;b01eda8e-b20e-49e9-afbd-22ebfaefcb6d)\n\nRepository Not Found for url: https://huggingface.co/sparse_opt/opt-125m/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dcf07a4c3b56>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_dn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOPTForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/opt-125m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load sparse model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOPTForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sparse_opt/opt-125m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# init tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/opt-125m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3506\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   3507\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3508\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: sparse_opt/opt-125m is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "# load dense model\n",
        "model_dn = OPTForCausalLM.from_pretrained('facebook/opt-125m', torch_dtype='auto').to(device)\n",
        "# load sparse model\n",
        "model_sp = OPTForCausalLM.from_pretrained('sparse_opt/opt-125m', torch_dtype='auto').to(device)\n",
        "# init tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-125m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqskug9-mXtR"
      },
      "outputs": [],
      "source": [
        "input_text = \"It takes a great deal of bravery\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS7YWAAhnatI"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w61F2J0QoPTi"
      },
      "source": [
        "Completion by dense model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_xY5fSSnK2I"
      },
      "outputs": [],
      "source": [
        "output_ids = model_dn.generate(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRmGPG1tnoci"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(output_ids[0].cpu(), skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Zk6UaQpP9C"
      },
      "source": [
        "Completion by sparse model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky5U9elZn-pL"
      },
      "outputs": [],
      "source": [
        "output_ids = model_sp.generate(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azFoDFrxpSJJ"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(output_ids[0].cpu(), skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}